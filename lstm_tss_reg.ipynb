{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data from the uploaded CSV file\n",
    "data_path = 'out.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Display the first few rows of the dataset and its structure\n",
    "#data.head(), data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1268 entries, 0 to 877\n",
      "Data columns (total 21 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   activity                      1268 non-null   float64\n",
      " 1   circumplex.arousal            1268 non-null   float64\n",
      " 2   circumplex.valence            1268 non-null   float64\n",
      " 3   appCat.builtin                1268 non-null   float64\n",
      " 4   appCat.communication          1268 non-null   float64\n",
      " 5   appCat.entertainment          1268 non-null   float64\n",
      " 6   appCat.finance                1268 non-null   float64\n",
      " 7   appCat.game                   1268 non-null   float64\n",
      " 8   appCat.office                 1268 non-null   float64\n",
      " 9   appCat.other                  1268 non-null   float64\n",
      " 10  appCat.social                 1268 non-null   float64\n",
      " 11  appCat.travel                 1268 non-null   float64\n",
      " 12  appCat.unknown                1268 non-null   float64\n",
      " 13  appCat.utilities              1268 non-null   float64\n",
      " 14  appCat.weather                1268 non-null   float64\n",
      " 15  call                          1268 non-null   float64\n",
      " 16  sms                           1268 non-null   float64\n",
      " 17  3_day_avg_mood                1268 non-null   float64\n",
      " 18  3_day_avg_activity            1268 non-null   float64\n",
      " 19  productivity_to_social_ratio  1268 non-null   float64\n",
      " 20  mood_shifted                  1267 non-null   float64\n",
      "dtypes: float64(21)\n",
      "memory usage: 217.9 KB\n",
      "     activity  circumplex.arousal  circumplex.valence  appCat.builtin  \\\n",
      "0    0.081548           -0.250000            0.750000             0.0   \n",
      "1    0.081548            0.000000            0.333333             0.0   \n",
      "635  0.042303            0.500000            2.000000             0.0   \n",
      "281  0.005556            0.000000            0.333333             0.0   \n",
      "636  0.042303            0.666667            1.333333             0.0   \n",
      "\n",
      "     appCat.communication  appCat.entertainment  appCat.finance  appCat.game  \\\n",
      "0                     0.0                   0.0             0.0          0.0   \n",
      "1                     0.0                   0.0             0.0          0.0   \n",
      "635                   0.0                   0.0             0.0          0.0   \n",
      "281                   0.0                   0.0             0.0          0.0   \n",
      "636                   0.0                   0.0             0.0          0.0   \n",
      "\n",
      "     appCat.office  appCat.other  ...  appCat.travel  appCat.unknown  \\\n",
      "0              0.0           0.0  ...            0.0             0.0   \n",
      "1              0.0           0.0  ...            0.0             0.0   \n",
      "635            0.0           0.0  ...            0.0             0.0   \n",
      "281            0.0           0.0  ...            0.0             0.0   \n",
      "636            0.0           0.0  ...            0.0             0.0   \n",
      "\n",
      "     appCat.utilities  appCat.weather  call    sms  3_day_avg_mood  \\\n",
      "0                 0.0             0.0   1.0   2.00        6.250000   \n",
      "1                 0.0             0.0   2.5   1.75        6.250000   \n",
      "635               0.0             0.0   5.0   1.50        7.000000   \n",
      "281               0.0             0.0   1.0  10.00        6.333333   \n",
      "636               0.0             0.0   1.0   1.00        7.000000   \n",
      "\n",
      "     3_day_avg_activity  productivity_to_social_ratio  mood_shifted  \n",
      "0              0.081548                           1.0           NaN  \n",
      "1              0.081548                           1.0      6.250000  \n",
      "635            0.042303                           1.0      7.333333  \n",
      "281            0.005556                           1.0      5.500000  \n",
      "636            0.042303                           1.0      7.000000  \n",
      "\n",
      "[5 rows x 21 columns] None\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "data['mood_shifted'] = data['mood'].shift(1)\n",
    "data.sort_values('date', inplace=True)\n",
    "\n",
    "features = data.drop(['mood', 'id', 'screen', 'Unnamed: 0', 'mood_quantiles', 'date'], axis=1)\n",
    "\n",
    "target = data['mood']\n",
    "print(features.head(), features.info())\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "#features_scaled = scaler.fit_transform(features)\n",
    "features_scaled = scaler.fit_transform(features.fillna(features.mean())) # Function to create sequences\n",
    "\n",
    "\n",
    "# Convert to numpy arrays\n",
    "features_np = np.array(features_scaled)\n",
    "target_np = np.array(target)\n",
    "\n",
    "# Create sequences for LSTM\n",
    "def create_sequences(features, target, window_size):\n",
    "    X, y = [], []\n",
    "    for i in range(len(features) - window_size):\n",
    "        X.append(features[i:(i + window_size)])\n",
    "        y.append(target[i + window_size])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Assuming we use a window size of 10 days\n",
    "window_size = 10\n",
    "X, y = create_sequences(features_np, target_np, window_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 213 samples, validating on 209 samples.\n",
      "VALIDATION: Average MSE: 1.964, Average MAE: 1.217\n",
      "Training on 422 samples, validating on 209 samples.\n",
      "VALIDATION: Average MSE: 0.835, Average MAE: 0.606\n",
      "Training on 631 samples, validating on 209 samples.\n",
      "VALIDATION: Average MSE: 0.605, Average MAE: 0.558\n",
      "Training on 840 samples, validating on 209 samples.\n",
      "VALIDATION: Average MSE: 0.603, Average MAE: 0.584\n",
      "Training on 1049 samples, validating on 209 samples.\n",
      "VALIDATION: Average MSE: 0.492, Average MAE: 0.523\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split, Subset\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import numpy as np\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# Create a TensorDataset\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "n_splits = 5\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "# Define the LSTM model class\n",
    "class LSTMModel(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim=1, num_layers=1):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = torch.nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.linear = torch.nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = self.linear(lstm_out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X_batch)\n",
    "            y_pred = y_pred.squeeze(-1)  # Squeeze the prediction to remove the extra dimension\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    mse_criterion = torch.nn.MSELoss()\n",
    "    mae_criterion = torch.nn.L1Loss()\n",
    "\n",
    "    total_mse = 0.0\n",
    "    total_mae = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            y_pred = model(X_batch)\n",
    "            y_pred = y_pred.squeeze(-1)  # Ensure prediction matches target shape\n",
    "\n",
    "            mse = mse_criterion(y_pred, y_batch)\n",
    "            mae = mae_criterion(y_pred, y_batch)\n",
    "\n",
    "            total_mse += mse.item()\n",
    "            total_mae += mae.item()\n",
    "\n",
    "    # Calculate average losses\n",
    "    avg_mse = total_mse / len(val_loader)\n",
    "    avg_mae = total_mae / len(val_loader)\n",
    "\n",
    "    return avg_mse, avg_mae\n",
    "\n",
    "# Usage example\n",
    "# Assuming model and val_loader have been defined and set up correctly\n",
    "\n",
    "\n",
    "\n",
    "# Model parameters (you need to define these correctly based on your problem)\n",
    "input_dim = 21\n",
    "hidden_dim = 50\n",
    "output_dim = 1\n",
    "batch_size = 32\n",
    "\n",
    "# LSTM model instance\n",
    "model = LSTMModel(input_dim, hidden_dim, output_dim)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "fold = 0\n",
    "for train_index, val_index in tscv.split(X_tensor):\n",
    "    train_dataset = Subset(dataset, train_index)\n",
    "    val_dataset = Subset(dataset, val_index)\n",
    "\n",
    "    # Create DataLoaders for training and validation sets\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    print(f\"Training on {len(train_dataset)} samples, validating on {len(val_dataset)} samples.\")\n",
    "\n",
    "    # Train the model\n",
    "    train_model(model, train_loader, criterion, optimizer)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    avg_mse, avg_mae = evaluate(model, val_loader)\n",
    "    print(f\"VALIDATION: Average MSE: {avg_mse:.3f}, Average MAE: {avg_mae:.3f}\")\n",
    "    fold += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m mean_squared_error, mean_absolute_error\n\u001b[1;32m      4\u001b[0m \u001b[39m# Get predictions and actuals for the validation set\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m actuals, predictions \u001b[39m=\u001b[39m get_predictions(model, val_loader)\n\u001b[1;32m      7\u001b[0m \u001b[39m# Calculate Mean Squared Error\u001b[39;00m\n\u001b[1;32m      8\u001b[0m mse \u001b[39m=\u001b[39m mean_squared_error(actuals, predictions)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "# Get predictions and actuals for the validation set\n",
    "actuals, predictions = get_predictions(model, val_loader)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(actuals, predictions)\n",
    "\n",
    "# Calculate Mean Absolute \n",
    "mae = mean_absolute_error(actuals, predictions)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1fc5637e3ed7126acd7dd2028bdbbd129c1d81b498282e5e8aaa91e63254f603"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
