{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170ecdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa930e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset_mood_smartphone.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e502b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214a0dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0173dcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbfc09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd307ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time'] = pd.to_datetime(df['time'])\n",
    "df['date'] = df['time'].dt.date\n",
    "df.rename(columns={'Unnamed: 0': 'index'}, inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f21646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df' is your DataFrame that includes a 'variable' column\n",
    "variable_values_list = df['variable'].unique().tolist()\n",
    "\n",
    "# Now 'variable_values_list' contains all unique variable values as a list\n",
    "print(variable_values_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4b18b7",
   "metadata": {},
   "source": [
    "# Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6950dafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the figure to plot histograms for a subset of variables\n",
    "fig, axs = plt.subplots(7, 3, figsize=(20, 40))\n",
    "axs = axs.flatten()  # Flatten the array for easy iteration\n",
    "\n",
    "# Selecting a manageable subset of variables for histograms\n",
    "#scores = ['mood', 'circumplex.arousal', 'circumplex.valence','activity']  # Adjust based on how many you wish to plot\n",
    "variables = [\n",
    "    'mood', 'circumplex.arousal', 'circumplex.valence', 'activity', 'screen', 'call', 'sms',\n",
    "    'appCat.builtin', 'appCat.communication', 'appCat.entertainment', 'appCat.finance', 'appCat.game',\n",
    "    'appCat.office', 'appCat.other', 'appCat.social', 'appCat.travel', 'appCat.unknown',\n",
    "    'appCat.utilities', 'appCat.weather'\n",
    "]\n",
    "\n",
    "for ax, variable in zip(axs, variables):\n",
    "    var_df = df[df['variable'] == variable]\n",
    "    ax.hist(var_df['value'], color='skyblue', edgecolor='black')\n",
    "    ax.set_title(variable)\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c673f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataset for mood, arousal, and valence\n",
    "mood_data = df[df['variable'] == 'mood']\n",
    "arousal_data = df[df['variable'] == 'circumplex.arousal']\n",
    "valence_data = df[df['variable'] == 'circumplex.valence']\n",
    "activity_data = df[df['variable'] == 'activity']\n",
    "\n",
    "# Check the range of values and presence of NaN values for mood, arousal, and valence\n",
    "mood_range = (mood_data['value'].min(), mood_data['value'].max(), mood_data['value'].isnull().sum(axis = 0))\n",
    "arousal_range = (arousal_data['value'].min(), arousal_data['value'].max(), arousal_data['value'].isnull().sum(axis = 0))\n",
    "valence_range = (valence_data['value'].min(), valence_data['value'].max(), valence_data['value'].isnull().sum(axis = 0))\n",
    "activity_range = (activity_data['value'].min(), activity_data['value'].max(), activity_data['value'].isnull().sum(axis = 0))\n",
    "\n",
    "mood_range, arousal_range, valence_range, activity_range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acebdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "mood_data['time'].nunique(), arousal_data['time'].nunique(), valence_data['time'].nunique(), activity_data['time'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3071c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mood_data['date'].nunique(), arousal_data['date'].nunique(), valence_data['date'].nunique(), activity_data['date'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf3500e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df' is your loaded DataFrame containing all the variables\n",
    "# Convert 'time' column to datetime if not already\n",
    "variables = [\n",
    "    'mood', 'circumplex.arousal', 'circumplex.valence', 'activity', 'screen', 'call', 'sms',\n",
    "    'appCat.builtin', 'appCat.communication', 'appCat.entertainment', 'appCat.finance', 'appCat.game',\n",
    "    'appCat.office', 'appCat.other', 'appCat.social', 'appCat.travel', 'appCat.unknown',\n",
    "    'appCat.utilities', 'appCat.weather'\n",
    "]\n",
    "# Get unique dates for each variable\n",
    "unique_dates = {var: df[df['variable'] == var]['date'].nunique() for var in variables}\n",
    "unique_times = {var: df[df['variable'] == var]['time'].nunique() for var in variables}\n",
    "\n",
    "# Identify the date range for each variable\n",
    "date_ranges = {var: (df[df['variable'] == var]['time'].min(), df[df['variable'] == var]['time'].max()) for var in variables}\n",
    "\n",
    "print(\"Unique Times:\", unique_times)\n",
    "print(\"Unique Dates:\", unique_dates)\n",
    "print(\"Date Ranges:\", date_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f67929b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_df = {\n",
    "    'Variable': [],\n",
    "    'Unique Times': [],\n",
    "    'Unique Dates': [],\n",
    "    'Date Range Start': [],\n",
    "    'Date Range End': []\n",
    "}\n",
    "\n",
    "# Populate the dictionary with data for each variable\n",
    "for var in variables:\n",
    "    data_for_df['Variable'].append(var)\n",
    "    data_for_df['Unique Times'].append(df[df['variable'] == var]['time'].nunique())\n",
    "    data_for_df['Unique Dates'].append(df[df['variable'] == var]['date'].nunique())\n",
    "    data_for_df['Date Range Start'].append(df[df['variable'] == var]['time'].min())\n",
    "    data_for_df['Date Range End'].append(df[df['variable'] == var]['time'].max())\n",
    "\n",
    "# Create the DataFrame\n",
    "variables_df = pd.DataFrame(data_for_df)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "variables_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8cd413",
   "metadata": {},
   "source": [
    "## nan values scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873b8497",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_rows_arousal = df[(df['variable'] == 'circumplex.arousal') & (df['value'].isna())].index\n",
    "nan_rows_valence = df[(df['variable'] == 'circumplex.valence') & (df['value'].isna())].index\n",
    "nan_rows_activity = df[(df['variable'] == 'activity') & (df['value'].isna())].index\n",
    "\n",
    "\n",
    "# Combine the indices of rows with NaN values for arousal and valence\n",
    "nan_rows_combined = nan_rows_arousal.union(nan_rows_valence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8b7cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_rows_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d5253e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nan = df.loc[nan_rows_combined]\n",
    "df_nan.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f2de35",
   "metadata": {},
   "source": [
    "## negative values in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0389297f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of variables/categories to check for negative values, excluding mood, arousal, and valence\n",
    "variables_to_check = [variable for variable in df['variable'].unique() if variable not in ['mood', 'circumplex.arousal', 'circumplex.valence']]\n",
    "\n",
    "# Check for negative values in the remaining variables\n",
    "negative_values_check = {variable: (df[df['variable'] == variable]['value'] < 0).any() for variable in variables_to_check}\n",
    "\n",
    "negative_values_check\n",
    "\n",
    "# Identify rows with negative values in appCat.builtin and appCat.entertainment in the original dataset\n",
    "negative_values_builtin = df[(df['variable'] == 'appCat.builtin') & (df['value'] < 0)].index\n",
    "negative_values_entertainment = df[(df['variable'] == 'appCat.entertainment') & (df['value'] < 0)].index\n",
    "\n",
    "#neg combined \n",
    "neg = negative_values_builtin.union(negative_values_entertainment)\n",
    "# Combine the indices of rows with negative values for appCat.builtin and appCat.entertainment\n",
    "# with previously identified NaN rows for removal\n",
    "remove_combined = nan_rows_combined.union(negative_values_builtin).union(negative_values_entertainment)\n",
    "\n",
    "df_negative = df.loc[neg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad3aa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da7580e",
   "metadata": {},
   "source": [
    "## nan scores plus neg times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331c577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = df.loc[remove_combined]\n",
    "\n",
    "combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0351a7e",
   "metadata": {},
   "source": [
    "# Clean datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed59b7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.drop(combined.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defa6d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df' is your loaded DataFrame containing all the variables\n",
    "# Convert 'time' column to datetime if not already\n",
    "variables = [\n",
    "    'mood', 'circumplex.arousal', 'circumplex.valence', 'activity', 'screen', 'call', 'sms',\n",
    "    'appCat.builtin', 'appCat.communication', 'appCat.entertainment', 'appCat.finance', 'appCat.game',\n",
    "    'appCat.office', 'appCat.other', 'appCat.social', 'appCat.travel', 'appCat.unknown',\n",
    "    'appCat.utilities', 'appCat.weather'\n",
    "]\n",
    "# Get unique dates for each variable\n",
    "unique_dates = {var: df1[df1['variable'] == var]['date'].nunique() for var in variables}\n",
    "unique_times = {var: df1[df1['variable'] == var]['time'].nunique() for var in variables}\n",
    "\n",
    "# Identify the date range for each variable\n",
    "date_ranges = {var: (df1[df1['variable'] == var]['time'].min(), df[df['variable'] == var]['time'].max()) for var in variables}\n",
    "\n",
    "print(\"Unique Times:\", unique_times)\n",
    "print(\"Unique Dates:\", unique_dates)\n",
    "print(\"Date Ranges:\", date_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d86c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_df1 = {\n",
    "    'Variable': [],\n",
    "    'Unique Times': [],\n",
    "    'Unique Dates': [],\n",
    "    'Date Range Start': [],\n",
    "    'Date Range End': []\n",
    "}\n",
    "\n",
    "# Populate the dictionary with data for each variable\n",
    "for var in variables:\n",
    "    data_for_df1['Variable'].append(var)\n",
    "    data_for_df1['Unique Times'].append(df[df['variable'] == var]['time'].nunique())\n",
    "    data_for_df1['Unique Dates'].append(df[df['variable'] == var]['date'].nunique())\n",
    "    data_for_df1['Date Range Start'].append(df[df['variable'] == var]['time'].min())\n",
    "    data_for_df1['Date Range End'].append(df[df['variable'] == var]['time'].max())\n",
    "\n",
    "# Create the DataFrame\n",
    "variables_df1 = pd.DataFrame(data_for_df)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "variables_df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4f2a45",
   "metadata": {},
   "source": [
    "### scores and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4350d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_variables = [\"mood\", \"circumplex.arousal\", \"circumplex.valence\", \"activity\"]\n",
    "\n",
    "# Creating a dataset with only the selected variables\n",
    "df_score = df1[df1['variable'].isin(score_variables)]\n",
    "\n",
    "# Creating another dataset with the rest of the variables\n",
    "df_machine = df1[~df1['variable'].isin(score_variables)]\n",
    "\n",
    "df_score['date'] = df_score['time'].dt.date\n",
    "df_machine['date'] = df_machine['time'].dt.date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48401eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175b5555",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores_daily = df_score.drop('time', axis = 1)\n",
    "df_machine_daily = df_machine.drop('time', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b97a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores_daily\n",
    "#df_scores_daily.to_csv('scores_daily.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea11744",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_scores = df_scores_daily.groupby(['id', 'date', 'variable'])['value'].mean().reset_index()\n",
    "grouped_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bd8e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "piv_scores = df_scores_daily.groupby(['id','date', 'variable'])['value'].mean().unstack()\n",
    "#grouped_activities = df_scores_daily.groupby(['id','date', 'variable'])['value'].mean().unstack().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ba6be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_times = df_machine_daily.groupby(['id', 'date', 'variable'])['value'].sum().reset_index()\n",
    "#grouped_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe30e203",
   "metadata": {},
   "outputs": [],
   "source": [
    "piv_times = df_machine_daily.groupby(['id','date', 'variable'])['value'].sum().unstack()\n",
    "#piv_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c2c1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "piv_times.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589100fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_machine_daily.to_csv('time_daily.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6c8e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores_daily['id'].nunique(), df_scores_daily['date'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cec867",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_machine_daily['id'].nunique(), df_machine_daily['date'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98ca8fa",
   "metadata": {},
   "source": [
    "### pivot scores and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e5c6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_pivot_df = df_scores_daily.pivot_table(index=['id','date'], columns='variable', values='value', aggfunc='mean').reset_index()\n",
    "#scores_pivot_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2014216",
   "metadata": {},
   "source": [
    "### time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2476f878",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_pivot_df = df_machine_daily.pivot_table(index=['id','date'], columns='variable', values='value', aggfunc='sum').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eea052",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_pivot_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081ece4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_categories_columns = [\n",
    "    \"appCat.builtin\", \"appCat.communication\", \"appCat.entertainment\",\n",
    "    \"appCat.finance\", \"appCat.game\", \"appCat.office\", \"appCat.other\",\n",
    "    \"appCat.social\", \"appCat.travel\", \"appCat.unknown\", \"appCat.utilities\",\n",
    "    \"appCat.weather\"\n",
    "]\n",
    "\n",
    "# Ensure the DataFrame has these columns; this prevents KeyError if some columns don't exist\n",
    "existing_app_columns = [col for col in app_categories_columns if col in time_pivot_df.columns]\n",
    "\n",
    "# Replace NaN values with 0 for the specified app category columns\n",
    "time_pivot_df[existing_app_columns] = time_pivot_df[existing_app_columns].fillna(0)\n",
    "#time_pivot_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7565ecae",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_interpolate = ['call',  'sms']\n",
    "\n",
    "# Perform linear interpolation on the specified columns\n",
    "time_pivot_df[columns_to_interpolate] = time_pivot_df[columns_to_interpolate].interpolate(method='linear', limit_direction='forward', axis=0)\n",
    "\n",
    "# Perform linear interpolation on the specified columns\n",
    "time_pivot_df[columns_to_interpolate] = time_pivot_df[columns_to_interpolate].interpolate(method='linear', limit_direction='backward', axis=0)\n",
    "time_pivot_df\n",
    "time_pivot_df.to_csv('out.csv') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c831ab25",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(scores_pivot_df, time_pivot_df, on=['id','date'], how='inner')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f6bf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_interpolate = ['call', 'sms']\n",
    "\n",
    "# Perform linear interpolation on the specified columns\n",
    "merged_df[columns_to_interpolate] = merged_df[columns_to_interpolate].interpolate(method='linear', limit_direction='forward', axis=0)\n",
    "\n",
    "# Perform linear interpolation on the specified columns\n",
    "merged_df[columns_to_interpolate] = merged_df[columns_to_interpolate].interpolate(method='linear', limit_direction='backward', axis=0)\n",
    "merged_df.to_csv('out.csv') \n",
    "merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b91bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_check = ['mood']\n",
    "\n",
    "\n",
    "df_cleaned = merged_df.dropna(subset=columns_to_check)\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880d4619",
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns_to_interpolate = ['activity']\n",
    "\n",
    "# Perform linear interpolation on the specified columns\n",
    "#df_cleaned[columns_to_interpolate] = df_cleaned[columns_to_interpolate].interpolate(method='linear', limit_direction='forward', axis=0)\n",
    "#df_cleaned[columns_to_interpolate] = df_cleaned[columns_to_interpolate].interpolate(method='linear', limit_direction='backward', axis=0)\n",
    "#df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda13e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_null_columns = [\"circumplex.valence\"]\n",
    "\n",
    "# Ensure the DataFrame has these columns; this prevents KeyError if some columns don't exist\n",
    "existing_app_columns = [col for col in not_null_columns if col in df_cleaned.columns]\n",
    "\n",
    "# Replace NaN values with 0 for the specified app category columns\n",
    "df_cleaned[existing_app_columns] = df_cleaned[existing_app_columns].fillna(0)\n",
    "df_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730f9919",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cca721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4c2029",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned.drop(\"activity\", axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df11b89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10f879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.to_csv('cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0c3439",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_cat_columns = [col for col in df_cleaned.columns if 'appCat.' in col]\n",
    "\n",
    "df_cleaned['sum_app_categories'] = df_cleaned[app_cat_columns].sum(axis=1)\n",
    "\n",
    "df_summary = df_cleaned[['sum_app_categories', 'screen', 'call']].copy()\n",
    "df_summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 08:50:36) \n[Clang 10.0.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "1fc5637e3ed7126acd7dd2028bdbbd129c1d81b498282e5e8aaa91e63254f603"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
