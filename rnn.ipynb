{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   Unnamed: 0       id        date  circumplex.arousal  circumplex.valence  \\\n",
       " 0           0  AS14.01  2014-02-26               -0.25                0.75   \n",
       " 1           2  AS14.01  2014-03-21                0.20                0.20   \n",
       " 2           3  AS14.01  2014-03-22                0.60                0.50   \n",
       " 3           4  AS14.01  2014-03-23                0.20                0.80   \n",
       " 4           5  AS14.01  2014-03-24                0.80                0.00   \n",
       " \n",
       "    mood  appCat.builtin  appCat.communication  appCat.entertainment  \\\n",
       " 0  6.25           0.000                 0.000                 0.000   \n",
       " 1  6.20        3139.218              6280.890              1007.456   \n",
       " 2  6.40         731.429              4962.918                93.324   \n",
       " 3  6.80        1286.246              5237.319                94.346   \n",
       " 4  6.00         866.956              9270.629               976.971   \n",
       " \n",
       "    appCat.finance  ...  appCat.office  appCat.other  appCat.social  \\\n",
       " 0           0.000  ...          0.000         0.000          0.000   \n",
       " 1          49.544  ...        172.206       239.751       4508.500   \n",
       " 2          21.076  ...          0.000        98.143        439.632   \n",
       " 3          43.403  ...          0.000        72.823        900.839   \n",
       " 4          34.106  ...          3.010        66.558       3223.626   \n",
       " \n",
       "    appCat.travel  appCat.unknown  appCat.utilities  appCat.weather  call  \\\n",
       " 0          0.000             0.0             0.000           0.000   1.0   \n",
       " 1        915.445             0.0           598.754           0.000   6.0   \n",
       " 2         37.305             0.0           117.621           0.000   3.0   \n",
       " 3          0.000             0.0            30.086          30.386   6.5   \n",
       " 4        419.805             0.0           178.732           0.000  10.0   \n",
       " \n",
       "          screen   sms  \n",
       " 0           NaN  2.00  \n",
       " 1  17978.907000  1.25  \n",
       " 2   6142.161000  1.00  \n",
       " 3   6773.832001  1.00  \n",
       " 4  15047.351001  1.00  \n",
       " \n",
       " [5 rows x 21 columns],)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'out.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "data.head(), \n",
    "#data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/__/6x_r2ddd163c_j6x_mtwstbr0000gn/T/ipykernel_18765/703068430.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['screen'].fillna(data['screen'].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Convert 'date' to datetime\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "date_counts = data['date'].value_counts()\n",
    "id_counts = data['id'].value_counts()\n",
    "\n",
    "# Convert the Series to a DataFrame for better visualization (optional)\n",
    "date_counts_df = date_counts.reset_index()\n",
    "date_counts_df.columns = ['Date', 'Count']\n",
    "\n",
    "# Sort the DataFrame by the 'Date' column\n",
    "sorted_date_counts_df = date_counts_df.sort_values(by='Date')\n",
    "\n",
    "# Convert the Series to a DataFrame for better visualization (optional)\n",
    "id_counts_df = id_counts.reset_index()\n",
    "id_counts_df.columns = ['ID', 'Count']\n",
    "\n",
    "\n",
    "# Fill missing 'screen' values with the median\n",
    "data['screen'].fillna(data['screen'].median(), inplace=True)\n",
    "\n",
    "# Select features and target\n",
    "features = data.drop(['Unnamed: 0', 'id', 'date', 'mood'], axis=1)\n",
    "target = data['mood']\n",
    "\n",
    "sorted_date_counts_df.to_csv('date_counts_df.csv')\n",
    "id_counts_df.to_csv('id_counts_df.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data for each id on each day:\n",
      "id          AS14.01  AS14.02  AS14.03  AS14.05  AS14.06  AS14.07  AS14.08  \\\n",
      "date                                                                        \n",
      "2014-02-26    False     True     True     True     True     True     True   \n",
      "2014-03-04     True     True     True     True     True     True     True   \n",
      "2014-03-05     True     True     True     True     True     True     True   \n",
      "2014-03-06     True     True     True     True     True     True    False   \n",
      "2014-03-07     True     True     True     True     True     True    False   \n",
      "...             ...      ...      ...      ...      ...      ...      ...   \n",
      "2014-06-04     True     True     True     True     True     True     True   \n",
      "2014-06-05     True     True     True     True     True     True     True   \n",
      "2014-06-06     True     True     True     True     True     True     True   \n",
      "2014-06-07     True     True     True     True     True     True     True   \n",
      "2014-06-08     True     True     True     True     True     True     True   \n",
      "\n",
      "id          AS14.09  AS14.12  AS14.13  ...  AS14.24  AS14.25  AS14.26  \\\n",
      "date                                   ...                              \n",
      "2014-02-26     True     True     True  ...     True     True     True   \n",
      "2014-03-04     True     True     True  ...     True     True     True   \n",
      "2014-03-05     True     True     True  ...     True     True     True   \n",
      "2014-03-06     True     True     True  ...     True     True     True   \n",
      "2014-03-07     True     True     True  ...     True     True     True   \n",
      "...             ...      ...      ...  ...      ...      ...      ...   \n",
      "2014-06-04     True     True     True  ...    False     True     True   \n",
      "2014-06-05     True     True     True  ...    False     True     True   \n",
      "2014-06-06     True     True     True  ...    False     True     True   \n",
      "2014-06-07     True     True     True  ...    False     True     True   \n",
      "2014-06-08     True     True     True  ...    False     True     True   \n",
      "\n",
      "id          AS14.27  AS14.28  AS14.29  AS14.30  AS14.31  AS14.32  AS14.33  \n",
      "date                                                                       \n",
      "2014-02-26     True     True     True     True     True     True     True  \n",
      "2014-03-04     True     True     True     True     True     True     True  \n",
      "2014-03-05     True     True     True     True     True     True     True  \n",
      "2014-03-06     True     True     True     True     True     True     True  \n",
      "2014-03-07     True     True     True     True     True     True     True  \n",
      "...             ...      ...      ...      ...      ...      ...      ...  \n",
      "2014-06-04     True     True     True     True     True     True     True  \n",
      "2014-06-05     True     True     True     True     True     True     True  \n",
      "2014-06-06     True     True     True     True     True     True     True  \n",
      "2014-06-07     True     True     True     True     True     True     True  \n",
      "2014-06-08     True     True     True     True     True     True     True  \n",
      "\n",
      "[95 rows x 27 columns]\n",
      "Number of unique days: 95\n",
      "Number of unique ids: 27\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('out.csv')\n",
    "\n",
    "# Convert 'date' to datetime if it's not already\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "# Check if there's a row for every day for each id\n",
    "pivot = data.pivot_table(index='date', columns='id', values='mood', aggfunc='count')\n",
    "\n",
    "# Find missing entries\n",
    "missing_entries = pivot.isnull()\n",
    "\n",
    "# Print days and ids with missing data\n",
    "print(\"Missing data for each id on each day:\")\n",
    "print(missing_entries)\n",
    "\n",
    "# Optionally, check the number of unique days and ids\n",
    "print(\"Number of unique days:\", data['date'].nunique())\n",
    "print(\"Number of unique ids:\", data['id'].nunique())\n",
    "\n",
    "missing_entries.to_csv('missing_entries.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDs with complete data for every day: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/__/6x_r2ddd163c_j6x_mtwstbr0000gn/T/ipykernel_18765/1758442154.py:11: FutureWarning: The default value of observed=False is deprecated and will change to observed=True in a future version of pandas. Specify observed=False to silence this warning and retain the current behavior\n",
      "  pivot_table = data.pivot_table(index='date', columns='id', values='mood', aggfunc='count')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('out.csv')\n",
    "\n",
    "# Convert 'date' to datetime and 'id' to a categorical type for better processing\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "data['id'] = data['id'].astype('category')\n",
    "\n",
    "# Create a pivot table to count entries for each date and id\n",
    "pivot_table = data.pivot_table(index='date', columns='id', values='mood', aggfunc='count')\n",
    "\n",
    "# Find IDs that have data for every day (no missing values in their column)\n",
    "complete_data_ids = pivot_table.columns[~pivot_table.isnull().any()].tolist()\n",
    "\n",
    "# Output the IDs\n",
    "print(\"IDs with complete data for every day:\", len(complete_data_ids))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Splitting the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled, target, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(features, target, sequence_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(features) - sequence_length):\n",
    "        X.append(features[i: i + sequence_length])\n",
    "        y.append(target[i + sequence_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Define sequence length\n",
    "sequence_length = 7\n",
    "\n",
    "\n",
    "# Reset the indices of y_train and y_test\n",
    "y_train_reset = y_train.reset_index(drop=True)\n",
    "y_test_reset = y_test.reset_index(drop=True)\n",
    "\n",
    "# Create sequences for training and testing sets\n",
    "X_train_seq, y_train_seq = create_sequences(X_train, y_train, sequence_length)\n",
    "X_test_seq, y_test_seq = create_sequences(X_test, y_test, sequence_length)\n",
    "\n",
    "X_train_seq.shape, X_test_seq.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting indices on target arrays to align properly after shuffling\n",
    "y_train_reset = y_train.reset_index(drop=True)\n",
    "y_test_reset = y_test.reset_index(drop=True)\n",
    "\n",
    "# Create sequences for training and testing sets\n",
    "X_train_seq, y_train_seq = create_sequences(X_train, y_train_reset, sequence_length)\n",
    "X_test_seq, y_test_seq = create_sequences(X_test, y_test_reset, sequence_length)\n",
    "\n",
    "X_train_seq.shape, X_test_seq.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Building the RNN model\n",
    "model = Sequential([\n",
    "    LSTM(50, return_sequences=True, input_shape=(X_train_seq.shape[1], X_train_seq.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    LSTM(50, return_sequences=False),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Display model summary\n",
    "model.summary()\n",
    "\n",
    "model.fit(X_train_seq, y_train_seq, epochs=30, batch_size=32, validation_data=(X_test_seq, y_test_seq))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1fc5637e3ed7126acd7dd2028bdbbd129c1d81b498282e5e8aaa91e63254f603"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
